# [Toy Artificial Intelligence lab.](https://ladooniani.github.io/tailab/) 
 
 ![alt text](https://github.com/ladooniani/tailab/blob/master/assets/toy_artificial_intelligence_lab_logo.png)

**Toy Artificial Intelligence\
Research, innovation and technology development\
Intelligent systems and robotics laboratory**

#

![alt text](https://github.com/ladooniani/tailab/blob/master/assets/tai_lab_terbinari_cbm_project_logo.png)

## Terbinari CBM Tet.01 Operating program

[<img alt="TAI Lab." width="70px" src="https://github.com/ladooniani/terbinari-cbm/blob/main/image/terbinari-cbm-tet-lado-oniani-tai-lab-smb.png" />](https://github.com/ladooniani/terbinari) 


 
### ‚úîÔ∏è Content

 - [Software and device](#Software-and-device)
 - [Conversations](#Conversations)
 - [Overview](#Overview)
 - [Processing ](#Processing)
 - [Functionality](#Functionality)
 - [Research](#Research)

## Software and device

Terbinari operating program represents interactive training and conversation model, natural language processing, understanding and generation syntactic and semantic analysis/matching logic algorithms, and controller operating methods.

Artificial conversational entity performs input/output question-answering, learning, spoken dialog system with multi-function chat-bot interface and anthropomorphic humanoid robot Control Bot Mechanism animatronics operator. The cervical motility device implements mouth speech events motion and eyes/head tracking contact and response under facial detection/recognition process of computer vision.

The bot operates individual unique memory content updated by interlocutor input in frames of the system legal code. The answer defines output for dialogue as a tool of reflective analysis by returning efferent recall from human-like machine cognitive function. Embodies autonomous companion simulator as trainable virtual teaching assistant and agent of compensatory intercourse for various interactive communication tasks.
 
![alt text](https://github.com/ladooniani/tailab/blob/master/assets/terbinari-tet-cbm-0.jpg)

![alt text](https://github.com/ladooniani/tailab/blob/master/assets/terbinari-tet-cbm-2.jpg)


## NLP semantic analysis methods algorithms functions

The operated choice between methods occurs at the level of input processing or mode condition and enters into interconnected work under functions control interface. 

### Direct answer chain

The simple and rigidly logical method represents automatic direct question-answer exchange learning and dialog process where the basic principle is output the answer to the question if the answer exists or request the answer to the new question. 

    q1a. q1b. q1c‚Ä¶
    a1a. a1b. a1c...
    q2a. q2b. q2c‚Ä¶
    a2a. a2b. a2c...

To start training and conversation open input window and insert:

    user: how are you? 
    _bot: fine, and you?
    user: perfect
    _bot: what is "perfect"?

  Request indicates that the answer does not exist.
 
    user: just perfect
    _bot: your answer "just perfect" saved 

  Compound of answer to the question saved: 

    user: Perfect
    _bot: Just perfect

  Using ending mark for multiple answer: 

    _bot: what is "perfect"?
    user: just perfect. it is perfect. you are perfect. yes, perfect
    
    user: perfect
    _bot: you are perfect
    user: perfect
    _bot: it is perfect
  
   Getting of new answer to exist question requires asking to request for a new adding to answer/multi-answer for question:   

    user: ask
    _bot: I want to know, how to answer to the question "hello"
    user: hi. whats up. hello. hey
    _bot: if you ask "hello" I answer "hi"

"Definition answer" returns the answer to the subject with definition by determination of noun. 

"Inverse definition answer" returns attitude to the subject by inversion of attitude by pronoun and adjective. 

"Contextual question" returns the answer to the previous question context by conjunction. 

"Contextual answer" provides adding and request method to create and return contextual dialogue node output. 

"Vertical stair answer" can be defined as mode-dependent stochastic optimization, including borrowed functions from other methods, and processing with several types of output in case of the "no answer" condition. 

"Inference root algorithm" returns the meaning of the word or sentence by weighing noun links in the whole memory context. 

"Output appeal" outputs questions and answers from existing memory by program choice.  

Interactive training and conversation






 


"CQ" Contextual question
 
Answer with link to previous answer context by exist conjunction:

    user: who are you
    _bot: I am your friend              
    user: why?
    _bot: because I like you     

"CTX" Contextual answer

Adding of keyword "ctx" to question opens contextual answer creation sequence:

    user: how to teach "ctx"
    _bot: what to teach?              
    user: answers to questions
    _bot: how to teach?     
    user: insert questions. insert answers
    _bot: why to teach?   
    user: to teach me. to get conversation 

    user: how to teach?
    _bot: Insert answers
    user: what answers?
    _bot: answers to questions

"DA" Definition answer

Returns answer by definition of subject with basic question form:

    user: true (DAC)
    _bot: true is true       
    user: what is true? (DA)
    _bot: true is condition

"IDA" Inverse definition answer

Returns attitude to the subject by inversion of pronoun and adjective content:

    user: What is your favorite color? 
    _bot: My favorite color is green       

"OA" Output appeal 

Returns efferent output from assigned list or by own random or contextual choice:

_bot: mercury temperature is 801 fahrenheit

"VSA" Vertical stair answer

Processing appears during voice-to-voice mode when input result is ‚Äúanswer not found‚Äù condition and adding of new compound is not available. During text-to-text or text-to-voice modes, process returns exist answer to equal question, otherwise requests for the answer to the new question. During voice-to-voice mode input processing flows by the stair of conditions with incipient step which counts subject value and looks for containing answers with context in compound, while move to the terminal noun value, otherwise the ‚Äúanswer not found‚Äù condition becomes true.

"IRN" Inference root network

Call of process occurs with using of keyword "think". Inference root network is a way of determining the meaning of a word without direct link between the word and its meaning at the time of determining of this relation by detecting and counting of connections depth in the complete context of memory, and to confirm this size as a direct value if hypothesis determines the meaning of the word by looking and counting of derivative nouns, received from previous processing up to a certain depth of subsequent connections. This makes hypothesis value true. Counting of key values qualifies conclusion by the higher size in downward curve of connections and weighing of oppositions to define attitude in supposed answer with request of confirmation for new key in root matrix. Balancing training focuses on the dependencies of nouns to create efferent output, which analyzes and determines the meaning, and requires confirmation for strengthening the knowledge. 













## Download markdown pdf

üìÉ [Download pdf](https://)

## üíñ Support project

Your donation will help expand independent research workflow, improve the laboratory environment, and speed up the conceptual strategy process, which leads to more involved research in frames of related technology, forming an educational platform for creative/intellectual collaboration and search for other references.

To support the project follow the donation link: 

<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=GRGH6SL9EL72U">
  <img src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" alt="Donate with PayPal" /><br><br>
</a>

To get updates from research workflow, please follow us on social networks and subscribe to [YouTube channel](https://www.youtube.com/channel/UC0Z161RgR5KpwPLvEDzkk9Q?view_as=subscriber) 

  <a href="https://www.youtube.com/channel/UC0Z161RgR5KpwPLvEDzkk9Q/featured"> <img src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/youtube.svg" alt="Youtube" height="20" style="vertical-align:top; margin:4px"></a>
   <a href=" https://www.facebook.com/terbinari" target="_blank" rel="noopener noreferrer"> <img src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/facebook.svg" alt="Facebook" height="20" style="vertical-align:top; margin:4px"></a>
   <a href="https://www.instagram.com/terbinari_cbm/" target="_blank" rel="noopener noreferrer"> <img src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/instagram.svg" alt="Instagram" height="20" style="vertical-align:top; margin:4px"></a>
  <a href="https://twitter.com/ArtificialToy" target="_blank" rel="noopener noreferrer"> <img src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/twitter.svg" alt="Twitter" height="20" style="vertical-align:top; margin:4px"></a>
   <a href="https://www.linkedin.com/company/tailab/" target="_blank" rel="noopener noreferrer"> <img src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg" alt="Linkedin" height="20" style="vertical-align:top; margin:4px"></a>
   
## Lab

### üî¨ [TAI lab](https://ladooniani.github.io/tailab/) 

<sub>üìÉ [TAI lab. Terbinari CBM project pdf](https://github.com/ladooniani/tailab/blob/master/docs/tai.pdf)<sub>

<sub>Copyright ¬© 2016-2021 Lado Oniani, TAI Lab. All Rights Reserved<sub>

 
